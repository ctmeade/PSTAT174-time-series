---
title: 'PSTAT 174 HW #5'
author: "Chris Meade"
date: "2/20/2017"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=T)
```

## Problem 1

Assume that the data are realized from an $AR(2)$ process. Then this process can be modelled as $$Y_t=\phi_1 Y_{t-1}+\phi_2 Y_{t-2} + Z_t$$

Let $\hat\gamma(0)=1382.2$, $\hat\gamma(1)=1114.4$, $\hat\gamma(2)=591.73$, and $\hat\gamma(3)=96.216$.

For an $AR(2)$ process, we have the following Yule Walker equations:

$$
\begin{bmatrix}
    \hat\gamma(0) & \hat\gamma(1) \\
    \hat\gamma(1) & \hat\gamma(0)
\end{bmatrix}
\begin{bmatrix}
    \hat\phi_1 \\
    \hat\phi_2
\end{bmatrix}
=
\begin{bmatrix}
    \hat\gamma(1) \\
    \hat\gamma(2)
\end{bmatrix}
$$

To find the estimates $\hat\phi_1$ and $\hat\phi_2$, we must invert the matrix.

$$
\begin{aligned}
\begin{bmatrix}
    \hat\phi_1 \\
    \hat\phi_2
\end{bmatrix}
&=
\begin{bmatrix}
    \hat\gamma(1) \\
    \hat\gamma(2)
\end{bmatrix}
\begin{bmatrix}
    \hat\gamma(0) & \hat\gamma(1) \\
    \hat\gamma(1) & \hat\gamma(0)
\end{bmatrix}^{-1} \\ \\
&=
\dfrac{1}{\hat\gamma(0)^2-\hat\gamma(1)^2}
\begin{bmatrix}
    \hat\gamma(0) & -\hat\gamma(1) \\
    -\hat\gamma(1) & \hat\gamma(0)
\end{bmatrix}
\begin{bmatrix}
    \hat\gamma(1) \\
    \hat\gamma(2)
\end{bmatrix}\\ \\
&=
\dfrac{1}{\hat\gamma(0)^2-\hat\gamma(1)^2}
\begin{bmatrix}
    \hat\gamma(0)\hat\gamma(1) & -\hat\gamma(1)\hat\gamma(2) \\
    -\hat\gamma(1)^2 & \hat\gamma(0)\hat\gamma(2)
\end{bmatrix}
\end{aligned}
$$

We now substitute in the estimators for our autocovariances to find the values of $\hat\phi_1$ and $\hat\phi_2$.

$$\hat\phi_1=\dfrac{\hat\gamma(0)\hat\gamma(1)-\hat\gamma(2)\hat\gamma(1)}{\hat\gamma(0)^2-\hat\gamma(1)^2}=1.3175$$

$$\hat\phi_2=\dfrac{\hat\gamma(0)\hat\gamma(2)-\hat\gamma(1)^2}{\hat\gamma(0)^2-\hat\gamma(1)^2}=-0.6342
$$

Finally,

$$
\begin{aligned}
\hat\sigma^2&=\hat\gamma(0)-
\begin{bmatrix}
    \hat\phi_1 & \hat\phi_2
\end{bmatrix}
\begin{bmatrix}
    \hat\gamma(1) \\
    \hat\gamma(2)
\end{bmatrix} \\ 
&= \hat\gamma(0)-\hat\phi_1\hat\gamma(1)-\hat\phi_2\hat\gamma(2) \\
&= 289.253
\end{aligned}
$$

We may now construct confidence intervals for $\phi_1$ and $\phi_2$. Since the sample of data points is sufficiently large, we may write that 

$$ 
\begin{aligned}
\hat\phi_1,\ \hat\phi_2 &\sim N(\begin{bmatrix}\phi_1 & \phi_2 \end{bmatrix},
\dfrac{\sigma^2}{\hat\gamma(0)^2-\hat\gamma(1)^2}
\begin{bmatrix}
    \hat\gamma(0) & -\hat\gamma(1) \\
    -\hat\gamma(1) & \hat\gamma(0)
\end{bmatrix}/100) \\
&\sim N(\begin{bmatrix}\phi_1 & \phi_2 \end{bmatrix}, 0.0063)
\end{aligned}
$$

This yields the following intervals:
$$
\begin{aligned}
I_{\phi_1}&=\hat\phi_1\pm Z_{0.025}\sqrt{0.0063}\\
&= 1.3175\pm 1.96\sqrt{0.0063}
&= 1.3175\pm 0.15557
\end{aligned}
$$

and

$$ 
\begin{aligned}
I_{\phi_2}&=\hat\phi_2\pm Z_{0.025}\sqrt{0.0063}\\
&= -0.6342\pm 1.96\sqrt{0.0063}
&= -0.6342\pm 0.15557
\end{aligned}
$$

## Problem 2

We begin calculation of the partial autocorrelations $\hat\phi_{11}$, $\hat\phi_{22}$, and $\hat\phi_{33}$ by setting 

$$\hat\phi_{11}=\hat\rho(1)=\dfrac{\hat\gamma(1)}{\hat\gamma(0)}=0.806$$

By definition of the Durben-Levinson Algorithm,

$$\hat\phi_{22}=\dfrac{\hat\rho(2)-\hat\phi_{11}\hat\rho(1)}{1-\hat\phi_{11}\hat\rho(1)}=
\dfrac{0.428-(0.806)^2}{1-(0.806)^2}=-0.633$$

and

$$\hat\phi_{21}=\hat\phi_{11}-\hat\phi_{22}\hat\phi_{11}=1.316$$

Finally we compute $\hat\phi_{33}$.

$$\hat\phi_{33}=\dfrac{\hat\rho(3)-\hat\phi_{21} \hat\rho(2)-\hat\phi_{22}\hat\rho(1)}{1-\hat\phi_{21} \hat\rho(1)-\hat\phi_{22} \hat\rho(2)}=0.081$$

To check if the value of $\hat\phi_{33}$ is compatible with the hypothesis that the data are generated from an $AR(2)$ process, we may assume that $\hat\phi_{33}\sim N(0,\dfrac{1}{100})$. We now construct a $95\%$ confidence interval.

$$I_{\phi_{33}}=\hat\phi_{33}\mp Z_{0.025}\sqrt{1/100}=0.081\mp 1.96(0.1)=(-0.115,0.277)$$

If these data were generated by an $AR(2)$ process, we would expect $\phi_{33}=0$. Since $0\in I_{\phi_{33}}$, our hypothesis is supported and we can conclude that the value of $\hat\phi_{33}$ is consistent with an $AR(2)$ model.

## Problem 3

```{r, eval=F}
# Get the current working directory
getwd()

# Set the working directory
setwd()

# Read data
read.table() or read.csv()

# Create Time-Series Object
ts()

# Plot at Time-Series Object
plot.ts()

# Simulate an ARMA Model
arima.sim()

# Add mean line to original time-series plot
abline(h=mean(ts, na.rm=T))

# Add trend line to original time-series plot
fit <- lm(ts ~ as.numeric(1:length(ts))) 
abline(fit)

# Calculate and Plot Theoretical ACFs and PACFs
ARMAacf(..., pacf = FALSE)
ARMAacf(..., pacf = TRUE)
plot(ARMAacf())

# Calculate and Plot Same ACFs and PACFs
acf(..., plot = TRUE)
pacf(..., plot = TRUE)

# Check for Model Causality / Invertibility
polyroot()

# Perform Box-Cox Tranformation
library(MASS)
t = 1:length(timeseries)
fit = lm(wine ~ t)
bcTransform = boxcox(timeseries ~ t,plotit = TRUE)

# Perform differencing at lags 1 and 12
diff(ts, lag = 1)
diff(ts, lag = 12)

# Perform Yule-Walker Estimations and find variance of estimates
fit <- ar(ts, method="yule-walker")

# Forecast future observations of a model
predict(ts,)

# Compare models using AICC:
AICc(fittedModel)
```